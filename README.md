# ğŸ“„ Round 1A: Understand Your Document

## ğŸš€ Overview

This solution processes a given PDF to extract a structured outline that includes the document **title** and its headings: **H1**, **H2**, and **H3** (with level and page number). It is designed to work offline, within 10 seconds for a 50-page PDF, and can be containerized for consistent and reproducible execution.

---

## ğŸ§  What It Does

The system:
- Automatically processes all PDFs in the `/app/input` folder.
- Uses a LightGBM-based ML model to classify PDF lines into headings (H1/H2/H3).
- Applies specific filters.
- Outputs structured JSON files in `/app/output`, with one `.json` for each `.pdf`.

---

## ğŸ—‚ Input/Output Example

### âœ… Input: PDF (placed inside `/app/input/`)
Supports English, Japanese, and mixed-script PDFs.

### âœ… Output: JSON (saved inside `/app/output/`)

```json
{
  "title": "Understanding AI",
  "outline": [
    { "level": "H1", "text": "Introduction", "page": 1 },
    { "level": "H2", "text": "What is AI?", "page": 2 },
    { "level": "H3", "text": "History of AI", "page": 3 }
  ]
}
```

---

## ğŸ› ï¸ How It Works

The model uses features such as:
- Positioning of Words
- Font size and boldness
- Capitalization (for Latin script)
- Font name and color
- Script type (Latin or Japanese)
- Sentence length.

It extracts this data using **PyMuPDF** (`fitz`) and feeds it into a LightGBM classifier.

---

## âš™ï¸ How to Run

### ğŸ³ Docker Execution

**Build the Docker image:**

```bash
docker build --platform linux/amd64 -t mysolutionname:somerandomidentifier .
```

**Run the Docker container:**

```bash
docker run --rm \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  --network none \
  mysolutionname:somerandomidentifier
```

### ğŸ Normal Python Execution (No Docker)

1. Install requirements:

```bash
pip install -r requirements.txt
```

2. Place your PDFs in the `input/` directory.

3. Run the script:

```bash
python main.py
```

4. Extracted JSON files will be saved in the `output/` directory.

---

## ğŸ§¾ Expected Behavior

For every file `/app/input/<filename>.pdf`, it generates `/app/output/<filename>.json`.

---

## ğŸ“¦ Dependencies

All dependencies are listed in `requirements.txt`:

- Python 3.10
- PyMuPDF
- pandas
- joblib
- lightgbm
- scikit-learn

---

## ğŸŒ Real-World Applications

This project is useful for building intelligent systems that understand the structure of documents. Real-world use cases include:

- ğŸ“š **Semantic search engines**: Enable users to search document sections based on headings.
- ğŸ§  **AI summarization tools**: Use extracted outlines to create summaries and navigation.
- ğŸ—‚ï¸ **Content classification and tagging**: Automatically categorize document sections for better indexing.
- ğŸ” **Document comparison**: Align sections between versions using structured outlines.
- ğŸ“Š **Data analytics dashboards**: Extract structured data from business reports, policy PDFs, research papers, etc.

---

## ğŸ“Œ Constraints Compliance

| Constraint               | Status âœ…        |
|-------------------------|------------------|
| â± Execution time        | â‰¤ 10s for 50 pages |
| ğŸ“¦ Model size            | â‰¤ 200MB           |
| ğŸŒ Network               | No internet used  |
| âš™ï¸ Runtime               | CPU (amd64)  |
| ğŸ“ I/O Format            | Per PDF â†’ Per JSON |

---

## âœ… Submission Checklist

- [x] Git project with working Dockerfile
- [x] All dependencies installed inside container
- [x] Output matches required JSON format
- [x] Docker-compatible execution (no internet, CPU-only)

